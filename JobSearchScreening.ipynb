{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195a6c0-7279-490c-9052-22d712874e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.19.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Using cached trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Using cached trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from selenium) (4.9.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Using cached selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
      "Using cached trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "Using cached trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-23.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.19.0 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c99290f-23b0-42ea-bcfc-974dd7f71287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the job keyword:  data analyst\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next page button not found or disabled. Exiting loop.\n",
      "                                          Job Position  \\\n",
      "0                                Treasury Data Analyst   \n",
      "1    Junior EMDI/CEDR Implementation & Quality Data...   \n",
      "2                               Marketing Data Analyst   \n",
      "3                                     Business Analyst   \n",
      "4                Analyst, Revenue Operations Reporting   \n",
      "..                                                 ...   \n",
      "224                         Investor Reporting Analyst   \n",
      "225  Senior Lead Data Management Analyst - Data Def...   \n",
      "226                 Pricing/Profit Improvement Analyst   \n",
      "227                               ERP Business Analyst   \n",
      "228                     Lead Senior Accounting Analyst   \n",
      "\n",
      "                                 Company Name  \\\n",
      "0                                    Comerica   \n",
      "1    American College of Emergency Physicians   \n",
      "2                                Smartfox LLC   \n",
      "3                                  LA Fitness   \n",
      "4                                     Equinix   \n",
      "..                                        ...   \n",
      "224             Shellpoint Mortgage Servicing   \n",
      "225                               Wells Fargo   \n",
      "226                               TriMark USA   \n",
      "227                               HF Sinclair   \n",
      "228                           Service Experts   \n",
      "\n",
      "                                       Location             Job State Date  \\\n",
      "0               Hybrid work in Frisco, TX 75034    PostedPosted 7 days ago   \n",
      "1               Hybrid work in Irving, TX 75063  EmployerActive 3 days ago   \n",
      "2                      Hybrid work in Plano, TX  EmployerActive 3 days ago   \n",
      "3    Irving, TX 75039 (Freeport/Hackberry area)       EmployerActive Today   \n",
      "4                              Frisco, TX 75034          PostedJust posted   \n",
      "..                                          ...                        ...   \n",
      "224                                 Coppell, TX    PostedPosted 5 days ago   \n",
      "225                   Hybrid work in Irving, TX   PostedPosted 18 days ago   \n",
      "226                        Lewisville, TX 75067  PostedPosted 30+ days ago   \n",
      "227              Dallas, TX 75201 (Uptown area)   PostedPosted 20 days ago   \n",
      "228                        Richardson, TX 75081   PostedPosted 17 days ago   \n",
      "\n",
      "                                           Requirement  \n",
      "0    Provide data tracking and analytics in support...  \n",
      "1    Experience handling a full range of delegated ...  \n",
      "2    3-5 years of directly related experience is re...  \n",
      "3    Exceptional analytical and problem-solving ski...  \n",
      "4    Strong analytical skills with the ability to c...  \n",
      "..                                                 ...  \n",
      "224  Heavy use of Microsoft excel for data analysis...  \n",
      "225  Subject matter expertise on data governance, d...  \n",
      "226  3 – 5 years related experience.\\n Analyst will...  \n",
      "227  Advanced analytical and problem-solving skills...  \n",
      "228  Query data extractions from financial system a...  \n",
      "\n",
      "[229 rows x 5 columns]\n",
      "Data saved to data analyst_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to input the keyword\n",
    "keyword = input(\"Enter the job keyword: \")\n",
    "\n",
    "# Initialize Safari WebDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "# Website URL\n",
    "url = \"https://www.indeed.com\"\n",
    "\n",
    "# Open the URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the input box for \"What\" to be clickable\n",
    "input_what = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"text-input-what\"]')))\n",
    "\n",
    "# Click on the input box for \"What\"\n",
    "input_what.click()\n",
    "\n",
    "# Clear the existing text in \"What\" box if any\n",
    "input_what.clear()\n",
    "\n",
    "# Type \"Data analyst\" into the input box for \"What\"\n",
    "input_what.send_keys(keyword)\n",
    "\n",
    "# Find and click the search button\n",
    "search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"jobsearch\"]/div/div[2]/button')))\n",
    "search_button.click()\n",
    "\n",
    "# Initialize empty lists to store job positions, company names, and locations\n",
    "job_positions = []\n",
    "company_names = []\n",
    "locations = []\n",
    "job_state_dates = []\n",
    "requirements = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for the search results to load\n",
    "        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CLASS_NAME, 'jcs-JobTitle')))\n",
    "        \n",
    "        # Extract job positions, company names, and locations from the search results\n",
    "        job_elements = driver.find_elements(By.CLASS_NAME, 'jcs-JobTitle')\n",
    "        company_elements = driver.find_elements(By.XPATH, '//span[@data-testid=\"company-name\" and contains(@class, \"css-\") and contains(@class, \"eu4oa1w0\")]')\n",
    "        location_elements = driver.find_elements(By.XPATH, '//div[@data-testid=\"text-location\"]')\n",
    "        state_date_elements = driver.find_elements(By.XPATH, '//span[@data-testid=\"myJobsStateDate\"]')\n",
    "        requirement_elements = driver.find_elements(By.XPATH, '//div[@class=\"heading6 tapItem-gutter css-193h767 eu4oa1w0\"]')\n",
    "\n",
    "        \n",
    "        for i in range(len(job_elements)):\n",
    "            job_position = job_elements[i].text.split('(')[0].strip()  # Extract job position\n",
    "            job_positions.append(job_position)\n",
    "            \n",
    "            company_name = company_elements[i].text if i < len(company_elements) else \"\"  # Extract company name\n",
    "            company_names.append(company_name)\n",
    "            \n",
    "            location = location_elements[i].text if i < len(location_elements) else \"\"  # Extract location\n",
    "            locations.append(location)\n",
    "\n",
    "            job_state_date = state_date_elements[i].text.strip() if i < len(state_date_elements) else \"\"  # Extract job state date\n",
    "            job_state_dates.append(job_state_date)\n",
    "            \n",
    "            requirement = requirement_elements[i].text.strip() if i < len(requirement_elements) else \"\"  # Extract requirement\n",
    "            requirements.append(requirement)\n",
    "        \n",
    "        \n",
    "        # Find the \"Next\" page button and click it if available\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"jobsearch-JapanPage\"]/div/div[5]/div/div[1]/nav/ul/li[6]/a')))\n",
    "            if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "                break  # Exit the loop if the \"Next\" button is disabled\n",
    "\n",
    "            next_button.click()\n",
    "        except:\n",
    "            print(\"Next page button not found or disabled. Exiting loop.\")\n",
    "            break\n",
    "except:\n",
    "    print(\"An error occurred while waiting for search results. Quitting...\")\n",
    "finally:\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Ensure all lists have the same length by padding shorter lists with empty strings\n",
    "max_length = max(len(job_positions), len(company_names), len(locations), len(job_state_dates), len(requirements))\n",
    "job_positions += [''] * (max_length - len(job_positions))\n",
    "company_names += [''] * (max_length - len(company_names))\n",
    "locations += [''] * (max_length - len(locations))\n",
    "job_state_dates += [''] * (max_length - len(job_state_dates))\n",
    "requirements += [''] * (max_length - len(requirements))\n",
    "\n",
    "# Creating a DataFrame from the lists of job positions, company names, and locations\n",
    "df = pd.DataFrame({\n",
    "    'Job Position': job_positions,\n",
    "    'Company Name': company_names,\n",
    "    'Location': locations,  # Adding the Location column\n",
    "    'Job State Date': job_state_dates,\n",
    "    'Requirement': requirements  # Adding the Requirement column\n",
    "})\n",
    "\n",
    "# Printing the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "excel_filename = keyword + \"_results.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(\"Data saved to\", excel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a4ae30-3042-4748-bad7-91c9721d2725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Position</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job State Date</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Treasury Data Analyst</td>\n",
       "      <td>Comerica</td>\n",
       "      <td>Hybrid work in Frisco, TX 75034</td>\n",
       "      <td>PostedPosted 7 days ago</td>\n",
       "      <td>Provide data tracking and analytics in support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior EMDI/CEDR Implementation &amp; Quality Data...</td>\n",
       "      <td>American College of Emergency Physicians</td>\n",
       "      <td>Hybrid work in Irving, TX 75063</td>\n",
       "      <td>EmployerActive 3 days ago</td>\n",
       "      <td>Experience handling a full range of delegated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>Smartfox LLC</td>\n",
       "      <td>Hybrid work in Plano, TX</td>\n",
       "      <td>EmployerActive 3 days ago</td>\n",
       "      <td>3-5 years of directly related experience is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>LA Fitness</td>\n",
       "      <td>Irving, TX 75039 (Freeport/Hackberry area)</td>\n",
       "      <td>EmployerActive Today</td>\n",
       "      <td>Exceptional analytical and problem-solving ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyst, Revenue Operations Reporting</td>\n",
       "      <td>Equinix</td>\n",
       "      <td>Frisco, TX 75034</td>\n",
       "      <td>PostedJust posted</td>\n",
       "      <td>Strong analytical skills with the ability to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Investor Reporting Analyst</td>\n",
       "      <td>Shellpoint Mortgage Servicing</td>\n",
       "      <td>Coppell, TX</td>\n",
       "      <td>PostedPosted 5 days ago</td>\n",
       "      <td>Heavy use of Microsoft excel for data analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Senior Lead Data Management Analyst - Data Def...</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Hybrid work in Irving, TX</td>\n",
       "      <td>PostedPosted 18 days ago</td>\n",
       "      <td>Subject matter expertise on data governance, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Pricing/Profit Improvement Analyst</td>\n",
       "      <td>TriMark USA</td>\n",
       "      <td>Lewisville, TX 75067</td>\n",
       "      <td>PostedPosted 30+ days ago</td>\n",
       "      <td>3 – 5 years related experience.\\n Analyst will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ERP Business Analyst</td>\n",
       "      <td>HF Sinclair</td>\n",
       "      <td>Dallas, TX 75201 (Uptown area)</td>\n",
       "      <td>PostedPosted 20 days ago</td>\n",
       "      <td>Advanced analytical and problem-solving skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Lead Senior Accounting Analyst</td>\n",
       "      <td>Service Experts</td>\n",
       "      <td>Richardson, TX 75081</td>\n",
       "      <td>PostedPosted 17 days ago</td>\n",
       "      <td>Query data extractions from financial system a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Position  \\\n",
       "0                                Treasury Data Analyst   \n",
       "1    Junior EMDI/CEDR Implementation & Quality Data...   \n",
       "2                               Marketing Data Analyst   \n",
       "3                                     Business Analyst   \n",
       "4                Analyst, Revenue Operations Reporting   \n",
       "..                                                 ...   \n",
       "224                         Investor Reporting Analyst   \n",
       "225  Senior Lead Data Management Analyst - Data Def...   \n",
       "226                 Pricing/Profit Improvement Analyst   \n",
       "227                               ERP Business Analyst   \n",
       "228                     Lead Senior Accounting Analyst   \n",
       "\n",
       "                                 Company Name  \\\n",
       "0                                    Comerica   \n",
       "1    American College of Emergency Physicians   \n",
       "2                                Smartfox LLC   \n",
       "3                                  LA Fitness   \n",
       "4                                     Equinix   \n",
       "..                                        ...   \n",
       "224             Shellpoint Mortgage Servicing   \n",
       "225                               Wells Fargo   \n",
       "226                               TriMark USA   \n",
       "227                               HF Sinclair   \n",
       "228                           Service Experts   \n",
       "\n",
       "                                       Location             Job State Date  \\\n",
       "0               Hybrid work in Frisco, TX 75034    PostedPosted 7 days ago   \n",
       "1               Hybrid work in Irving, TX 75063  EmployerActive 3 days ago   \n",
       "2                      Hybrid work in Plano, TX  EmployerActive 3 days ago   \n",
       "3    Irving, TX 75039 (Freeport/Hackberry area)       EmployerActive Today   \n",
       "4                              Frisco, TX 75034          PostedJust posted   \n",
       "..                                          ...                        ...   \n",
       "224                                 Coppell, TX    PostedPosted 5 days ago   \n",
       "225                   Hybrid work in Irving, TX   PostedPosted 18 days ago   \n",
       "226                        Lewisville, TX 75067  PostedPosted 30+ days ago   \n",
       "227              Dallas, TX 75201 (Uptown area)   PostedPosted 20 days ago   \n",
       "228                        Richardson, TX 75081   PostedPosted 17 days ago   \n",
       "\n",
       "                                           Requirement  \n",
       "0    Provide data tracking and analytics in support...  \n",
       "1    Experience handling a full range of delegated ...  \n",
       "2    3-5 years of directly related experience is re...  \n",
       "3    Exceptional analytical and problem-solving ski...  \n",
       "4    Strong analytical skills with the ability to c...  \n",
       "..                                                 ...  \n",
       "224  Heavy use of Microsoft excel for data analysis...  \n",
       "225  Subject matter expertise on data governance, d...  \n",
       "226  3 – 5 years related experience.\\n Analyst will...  \n",
       "227  Advanced analytical and problem-solving skills...  \n",
       "228  Query data extractions from financial system a...  \n",
       "\n",
       "[229 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46649413-18d1-48ab-913d-0497245f185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/myueta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4edbb282-268b-4bad-b8a1-b37a45dffb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 most frequent words in 'Requirement' column:\n",
      "data: 279\n",
      "experience: 76\n",
      "years: 70\n",
      "business: 61\n",
      "skills: 43\n",
      "analysis: 37\n",
      "analyze: 36\n",
      "ability: 34\n",
      "strong: 33\n",
      "analyst: 29\n",
      "related: 28\n",
      "information: 28\n",
      "analytics: 24\n",
      "support: 22\n",
      "attention: 22\n",
      "detail: 22\n",
      "analytical: 22\n",
      "provide: 21\n",
      "sets: 19\n",
      "complex: 18\n",
      "working: 18\n",
      "accuracy: 16\n",
      "tx: 16\n",
      "role: 15\n",
      "work: 15\n",
      "large: 15\n",
      "job: 15\n",
      "process: 15\n",
      "employeractive: 12\n",
      "required: 12\n",
      "bachelors: 12\n",
      "degree: 12\n",
      "management: 12\n",
      "field: 12\n",
      "tools: 12\n",
      "commercial: 12\n",
      "technology: 12\n",
      "determine: 12\n",
      "requirements: 12\n",
      "manner: 12\n",
      "reports: 12\n",
      "knowledge: 12\n",
      "location: 12\n",
      "summary: 12\n",
      "prepare: 12\n",
      "identify: 12\n",
      "modeling: 10\n",
      "drive: 10\n",
      "query: 10\n",
      "various: 9\n",
      "tasks: 9\n",
      "exceptional: 9\n",
      "candidate: 9\n",
      "excellent: 9\n",
      "domain: 9\n",
      "industrial: 9\n",
      "needs: 9\n",
      "translate: 9\n",
      "actionable: 9\n",
      "insights: 9\n",
      "utilize: 9\n",
      "present: 9\n",
      "models: 9\n",
      "solutions: 9\n",
      "product: 9\n",
      "problem: 9\n",
      "andor: 9\n",
      "thinking: 9\n",
      "requires: 9\n",
      "team: 9\n",
      "problems: 9\n",
      "position: 9\n",
      "company: 9\n",
      "entertainment: 9\n",
      "quality: 9\n",
      "minimum: 9\n",
      "trends: 9\n",
      "use: 9\n",
      "tm: 9\n",
      "problemsolving: 7\n",
      "financial: 7\n",
      "seeking: 7\n",
      "development: 7\n",
      "advanced: 7\n",
      "dallas: 7\n",
      "reporting: 7\n",
      "perform: 7\n",
      "treasury: 6\n",
      "initiatives: 6\n",
      "streamline: 6\n",
      "improve: 6\n",
      "full: 6\n",
      "focus: 6\n",
      "directly: 6\n",
      "ensure: 6\n",
      "processes: 6\n",
      "stewardship: 6\n",
      "handson: 6\n",
      "collect: 6\n",
      "banking: 6\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample DataFrame (replace with your DataFrame)\n",
    "# df = pd.read_excel('your_dataframe.xlsx')\n",
    "\n",
    "# Sample stop words and additional words to delete\n",
    "del_words = set(stopwords.words('english'))\n",
    "del_words.update([\"days\",\"agomore\",\"postedposted\",\"posted\", \"ago\",\"postedjust\",\"postedmore\",\"including\"])\n",
    "\n",
    "# Function to clean text and tokenize into words\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.lower().split()  # Convert to lowercase and split into words\n",
    "    return [word for word in words if word not in del_words and not word.isdigit()]  # Remove stop words, additional words, and numbers\n",
    "\n",
    "# Clean and tokenize 'Requirement' column\n",
    "cleaned_requirements = df['Requirement'].apply(clean_text)\n",
    "\n",
    "# Flatten the list of lists into a single list of words\n",
    "all_words = [word for sublist in cleaned_requirements for word in sublist]\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Get the top 10 most frequent words\n",
    "top_100_words = word_freq.most_common(100)\n",
    "\n",
    "# Display the top 100 words\n",
    "print(\"Top 100 most frequent words in 'Requirement' column:\")\n",
    "for word, freq in top_100_words:\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbdd13-97e7-40cd-acb4-df67dccbabf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
